{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcbb4d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test Split: 60.0% train / 40.0% test\n",
      "Cross-validation scores: [0.84090909 0.88636364 0.88636364 0.95454545 0.90697674]\n",
      "Average accuracy: 0.8950317124735729\n",
      "Confusion Matrix:\n",
      "[[45  0  0  0  0  0]\n",
      " [ 0  7  0 16  0  1]\n",
      " [ 0  0 29  0  0  0]\n",
      " [ 1  0  0 19  0  0]\n",
      " [ 0  0  0  0 21  0]\n",
      " [ 0  0  0  0  0  8]]\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      "[[1.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.29166667 0.         0.66666667 0.         0.04166667]\n",
      " [0.         0.         1.         0.         0.         0.        ]\n",
      " [0.05       0.         0.         0.95       0.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         0.         1.        ]]\n",
      "\n",
      "Train/Test Split: 70.0% train / 30.0% test\n",
      "Cross-validation scores: [0.90384615 0.90196078 0.90196078 0.88235294 0.92156863]\n",
      "Average accuracy: 0.9023378582202112\n",
      "Confusion Matrix:\n",
      "[[34  0  0  0  0  0]\n",
      " [ 0  5  0 12  0  1]\n",
      " [ 0  0 22  0  0  0]\n",
      " [ 1  0  0 14  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  0  0  6]]\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      "[[1.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.27777778 0.         0.66666667 0.         0.05555556]\n",
      " [0.         0.         1.         0.         0.         0.        ]\n",
      " [0.06666667 0.         0.         0.93333333 0.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         0.         1.        ]]\n",
      "\n",
      "Train/Test Split: 80.0% train / 20.0% test\n",
      "Cross-validation scores: [0.89830508 0.91525424 0.89655172 0.94827586 0.87931034]\n",
      "Average accuracy: 0.9075394506136762\n",
      "Confusion Matrix:\n",
      "[[23  0  0  0  0  0]\n",
      " [ 0  3  0  8  0  1]\n",
      " [ 0  0 15  0  0  0]\n",
      " [ 1  0  0  9  0  0]\n",
      " [ 0  0  0  0 10  0]\n",
      " [ 0  0  0  0  0  4]]\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      "[[1.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.25       0.         0.66666667 0.         0.08333333]\n",
      " [0.         0.         1.         0.         0.         0.        ]\n",
      " [0.1        0.         0.         0.9        0.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.         0.         1.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Update the file path to the local dataset file\n",
    "file_path = r'C:\\Users\\pc\\Desktop\\lab 13 AI full\\dermatology.data'\n",
    "\n",
    "# Load the Dermatology dataset\n",
    "column_names = ['erythema', 'scaling', 'definite_borders', 'itching', 'koebner_phenomenon', 'polygonal_papules',\n",
    "                'follicular_papules', 'oral_mucosal_involvement', 'knee_and_elbow_involvement', 'scalp_involvement',\n",
    "                'family_history', 'melanin_incontinence', 'eosinophils_infiltrate', 'PNL_infiltrate',\n",
    "                'fibrosis_of_the_papillary_dermis', 'exocytosis', 'acanthosis', 'hyperkeratosis',\n",
    "                'parakeratosis', 'clubbing_of_the_rete_ridges', 'elongation_of_the_rete_ridges',\n",
    "                'thinning_of_the_suprapapillary_epidermis', 'spongiform_pustule', 'munro_microabcess',\n",
    "                'focal_hypergranulosis', 'disappearance_of_the_granular_layer', 'vacuolisation_and_damage_of_basal_layer',\n",
    "                'spongiosis', 'saw_tooth_appearance_of_retes', 'follicular_horn_plug', 'perifollicular_parakeratosis',\n",
    "                'inflammatory_monoluclear_inflitrate', 'band_like_infiltrate', 'age', 'class']\n",
    "data = pd.read_csv(file_path, names=column_names)\n",
    "\n",
    "# Preprocessing: separating features and target variable\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Replace '?' with NaN values\n",
    "X = X.replace('?', np.nan)\n",
    "\n",
    "# Impute missing values with the most frequent value\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Train/test split\n",
    "train_sizes = [0.6, 0.7, 0.8]\n",
    "for train_size in train_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, stratify=y, random_state=42)\n",
    "\n",
    "    # Na√Øve Bayes classification\n",
    "    nb_classifier = GaussianNB()\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    k = 5  # Number of folds\n",
    "    cv_scores = cross_val_score(nb_classifier, X_train, y_train, cv=StratifiedKFold(n_splits=k, shuffle=True))\n",
    "\n",
    "    # Display cross-validation scores\n",
    "    print(f\"Train/Test Split: {train_size * 100}% train / {100 - train_size * 100}% test\")\n",
    "    print(f\"Cross-validation scores: {cv_scores}\")\n",
    "    print(f\"Average accuracy: {cv_scores.mean()}\")\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix:\\n{confusion}\\n\")\n",
    "\n",
    "    # Normalize confusion matrix\n",
    "    normalized_confusion = confusion.astype('float') / confusion.sum(axis=1)[:, np.newaxis]\n",
    "    print(f\"Normalized Confusion Matrix:\\n{normalized_confusion}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c04539",
   "metadata": {},
   "outputs": [],
   "source": [
    "r'C:\\Users\\pc\\Desktop\\lab 13 AI full\\data_banknote_authentication"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
